{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku\n",
    "from keras.callbacks import EarlyStopping\n",
    "#TF_FORCE_GPU_ALLOW_GROWTH=True\n",
    "#import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique Quotes: (36197,)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('quotesFiltered.csv', sep=';')\n",
    "data = data.drop(data[data.QUOTE.str.count(\"\\.\") > 1].index) ## remove quotes with more than 1 sentence by counting dots\n",
    "data = data['QUOTE'].str.lower() ##makes all strings lowercase\n",
    "quotes = data.drop_duplicates()\n",
    "print(f\"Total Unique Quotes: {quotes.shape}\")\n",
    "\n",
    "\n",
    "all_quotes = list(quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words in the text corpus: 24212\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "def generate_sequences(corpus):\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    print(f\"Total unique words in the text corpus: {total_words}\")\n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        seq = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(seq)):\n",
    "            ngram_seq = seq[:i+1]\n",
    "            input_sequences.append(ngram_seq)\n",
    "            \n",
    "    return input_sequences, total_words\n",
    "\n",
    "# Generating sequences\n",
    "input_sequences, total_words = generate_sequences(all_quotes)\n",
    "input_sequences[:5]\n",
    "maxlen = max([len(x) for x in input_sequences])\n",
    "print(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictors and labels from the padded sequences\n",
    "#def generate_input_sequence(input_sequences):\n",
    "#    ##maxlen = max([len(x) for x in input_sequences])\n",
    "#    input_sequences = pad_sequences(input_sequences, maxlen=maxlen)\n",
    "#    predictors, label = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "#    label = ku.to_categorical(label, num_classes=total_words)\n",
    "#    return predictors, label  ##, maxlen\n",
    "#\n",
    "#predictors, label = generate_input_sequence(input_sequences)\n",
    "#predictors[:1], label[:1]\n",
    "#print(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the model\n",
    "#embedding_dim = 64\n",
    "#\n",
    "#def create_model(maxlen, embedding_dim, total_words):\n",
    "#    model = Sequential()\n",
    "#    model.add(layers.Embedding(total_words, embedding_dim, input_length = maxlen,mask_zero=False,))\n",
    "#    model.add(layers.LSTM(64, dropout=0.2))\n",
    "#    model.add(layers.Dense(total_words, activation='softmax'))\n",
    "#   \n",
    "#    # compiling the model\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#    return model\n",
    "#\n",
    "#model = create_model(maxlen, embedding_dim, total_words)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the model\n",
    "#model.fit(predictors, label, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for later use\n",
    "#model.save(\"Quotes_generator.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model1 = load_model(\"Quotes_generator_low_training.h5\") ## Trained 50 epochs on 10% of the dataset\n",
    "model2 = load_model(\"Quotes_generator_high_training.h5\") ## Trained 25 epochs on the full dataset in chunks of 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quote(seed_text, num_words, model, maxlen):\n",
    "    \n",
    "    for _ in range(num_words):\n",
    "        seed_text = seed_text.lower()\n",
    "        tokens = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        tokens = pad_sequences([tokens], maxlen=maxlen, padding='pre')\n",
    "        \n",
    "        predicted = model.predict_classes(tokens)\n",
    "        \n",
    "        output_word = ''\n",
    "        \n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text = seed_text + \" \" + output_word\n",
    "    \n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "\n",
    "\n",
    "wordCategories = ['wordLists/loveWords.txt', 'wordLists/politicsWords.txt', 'wordLists/ageWords.txt'] ## contains words related to a certain topic\n",
    "\n",
    "with open('wordLists/illegalWordsList.txt') as f:\n",
    "    temp = f.readlines()\n",
    "illegalWords = []\n",
    "for element in temp:\n",
    "    illegalWords.append(element.strip())\n",
    "\n",
    "\n",
    "def chooseStartingWord(wordCategories): ## chooses a random word from a chosen topic.\n",
    "    with open(random.choice(wordCategories)) as f:\n",
    "        words = f.readlines() \n",
    "    random_word = random.choice(words)\n",
    "    return random_word\n",
    "\n",
    "def removeDuplicates(sentence):\n",
    "    chars = list(sentence) ## if 2 duplicate words are next to each other, remove 1 of them\n",
    "    prev = None            ## so \"there is is is a fire fire\" --> \"there is a fire\"\n",
    "    k = 0\n",
    "    for c in sentence:\n",
    "        if prev != c:\n",
    "            chars[k] = c\n",
    "            prev = c\n",
    "            k = k + 1\n",
    "    return ' '.join(chars[:k])\n",
    "\n",
    "def filterQuote(quote, wordList):\n",
    "    x = True\n",
    "    words = quote.split() ## turn quote string into an array of words\n",
    "    while x == True:\n",
    "        if words[-1] in wordList: ## check if last word of sentence is legal or not\n",
    "            words = words[:-1]    ## if illegal, simply remove it.\n",
    "        else:\n",
    "            x = False\n",
    "            \n",
    "    words = removeDuplicates(words) ## filter duplicates\n",
    "    filteredQuote = words.capitalize() + '.' ## capitalization and punctuation\n",
    "    filteredQuote = re.sub(r'\\bi\\b', 'I', filteredQuote) ## regex baby, turns \"i\" into \"I\"\n",
    "    return filteredQuote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 :  Age in the where and the try and that of stand them in the very country.\n",
      "Model 2 :  Age is the key to the wisdom of the world and the world is the most.\n"
     ]
    }
   ],
   "source": [
    "startWord = 'Age'\n",
    "length = 15\n",
    "## not sure wether maxlen should be equal to number of words, or be longer. it was trained on maxlen ~= 80\n",
    "\n",
    "outputQuote = generate_quote(startWord, num_words = length, model= model1, maxlen=length)\n",
    "filteredQuote = filterQuote(outputQuote, illegalWordsList)\n",
    "print(\"Model 1 : \",filteredQuote)\n",
    "outputQuote2 = generate_quote(startWord, num_words = length, model= model2, maxlen=length)\n",
    "filteredQuote2 = filterQuote(outputQuote2, illegalWordsList)\n",
    "print(\"Model 2 : \",filteredQuote2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly chosen starting word:  time\n",
      "\n",
      "Model 1 :  Time in the see want to not wise we the very tender and will poet of.\n",
      "Model 2 :  Time is the truth that is the truth that all the time is the most important to.\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Randomly chosen starting word:  friendship\n",
      "\n",
      "Model 1 :  Friendship on one not a become cool man of quite a become way of from more programming a adore reach be.\n",
      "Model 2 :  Friendship is a fool to know the truth and another is not a fool to know the truth and yet he.\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Randomly chosen starting word:  passion\n",
      "\n",
      "Model 1 :  Passion while not the gathering defend and ourselves to also a architecture disappointment in that modern in I the secret and the almost and.\n",
      "Model 2 :  Passion is a weapon of the war of fighting vanguard has created in its war and customers and advanced technology and the same tasks.\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Randomly chosen starting word:  relationship\n",
      "\n",
      "Model 1 :  Relationship in a precisely them spirituality this the murder and the end in the reducing to held the end I system to change.\n",
      "Model 2 :  Relationship is the same thing to do it is to be a mistake to do it is a mistake to establish the quality.\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Randomly chosen starting word:  friendship\n",
      "\n",
      "Model 1 :  Friendship on one not a become cool lost an they felt one not dad to something a each no I will us of.\n",
      "Model 2 :  Friendship is a fool to know the truth and another is not a fool to know the truth and another is not for.\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < 5:\n",
    "    startingWord = chooseStartingWord(wordCategories)\n",
    "    print('Randomly chosen starting word: ',startingWord)\n",
    "    numberOfWords = random.randint(12,25)\n",
    "    startingWord = startingWord.strip()\n",
    "\n",
    "    outputQuote = generate_quote(startingWord, num_words = numberOfWords, model= model1, maxlen=numberOfWords)\n",
    "    filteredQuote = filterQuote(outputQuote, illegalWordsList)\n",
    "    outputQuote2 = generate_quote(startingWord, num_words = numberOfWords, model= model2, maxlen=numberOfWords)\n",
    "    filteredQuote2 = filterQuote(outputQuote2, illegalWordsList)\n",
    "    print(\"Model 1 : \",filteredQuote)\n",
    "    print(\"Model 2 : \",filteredQuote2)\n",
    "    i+= 1\n",
    "    print('------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
