{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1' ## might have to comment this out, gpu related\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku\n",
    "from keras.callbacks import EarlyStopping\n",
    "#TF_FORCE_GPU_ALLOW_GROWTH=True\n",
    "#import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique Quotes: (36197,)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('quotesFiltered.csv', sep=';')\n",
    "data = data.drop(data[data.QUOTE.str.count(\"\\.\") > 1].index) ## remove quotes with more than 1 sentence by counting dots\n",
    "data = data['QUOTE'].str.lower() ##makes all strings lowercase\n",
    "quotes = data.drop_duplicates()\n",
    "print(f\"Total Unique Quotes: {quotes.shape}\")\n",
    "\n",
    "\n",
    "all_quotes = list(quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words in the text corpus: 24212\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "def generate_sequences(corpus):\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    print(f\"Total unique words in the text corpus: {total_words}\")\n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        seq = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(seq)):\n",
    "            ngram_seq = seq[:i+1]\n",
    "            input_sequences.append(ngram_seq)\n",
    "            \n",
    "    return input_sequences, total_words\n",
    "\n",
    "# Generating sequences\n",
    "input_sequences, total_words = generate_sequences(all_quotes)\n",
    "input_sequences[:5]\n",
    "maxlen = max([len(x) for x in input_sequences])\n",
    "print(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictors and labels from the padded sequences\n",
    "#def generate_input_sequence(input_sequences):\n",
    "#    ##maxlen = max([len(x) for x in input_sequences])\n",
    "#    input_sequences = pad_sequences(input_sequences, maxlen=maxlen)\n",
    "#    predictors, label = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "#    label = ku.to_categorical(label, num_classes=total_words)\n",
    "#    return predictors, label  ##, maxlen\n",
    "#\n",
    "#predictors, label = generate_input_sequence(input_sequences)\n",
    "#predictors[:1], label[:1]\n",
    "#print(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the model\n",
    "#embedding_dim = 64\n",
    "#\n",
    "#def create_model(maxlen, embedding_dim, total_words):\n",
    "#    model = Sequential()\n",
    "#    model.add(layers.Embedding(total_words, embedding_dim, input_length = maxlen,mask_zero=False,))\n",
    "#    model.add(layers.LSTM(64, dropout=0.2))\n",
    "#    model.add(layers.Dense(total_words, activation='softmax'))\n",
    "#   \n",
    "#    # compiling the model\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#    return model\n",
    "#\n",
    "#model = create_model(maxlen, embedding_dim, total_words)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the model\n",
    "#model.fit(predictors, label, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for later use\n",
    "#model.save(\"Quotes_generator.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 64)            1549568   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 24212)             1573780   \n",
      "=================================================================\n",
      "Total params: 3,156,372\n",
      "Trainable params: 3,156,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model1 = load_model(\"Quotes_generator_low_training.h5\") ## Trained 50 epochs on 10% of the dataset\n",
    "model2 = load_model(\"Quotes_generator_high_training.h5\") ## Trained 25 epochs on the full dataset in chunks of 10\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quote(seed_text, num_words, model, maxlen):\n",
    "    \n",
    "    for _ in range(num_words):\n",
    "        seed_text = seed_text.lower()\n",
    "        tokens = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        tokens = pad_sequences([tokens], maxlen=maxlen, padding='pre')\n",
    "        \n",
    "        predicted = model.predict_classes(tokens)\n",
    "        \n",
    "        output_word = ''\n",
    "        \n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text = seed_text + \" \" + output_word\n",
    "    \n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "\n",
    "\n",
    "wordCategories = ['wordLists/loveWords.txt', 'wordLists/politicsWords.txt',\n",
    "                  'wordLists/randomWords.txt', 'wordLists/ageWords.txt'] ## contains words related to a certain topic\n",
    "\n",
    "with open('wordLists/illegalWordsList.txt') as f:\n",
    "    temp = f.readlines()\n",
    "illegalWords = []\n",
    "for element in temp:\n",
    "    illegalWords.append(element.strip())\n",
    "\n",
    "\n",
    "def chooseStartingWord(wordCategories): ## chooses a random word from a chosen topic.\n",
    "    temp = random.uniform(0, 1)\n",
    "    pronouns = ''\n",
    "    \n",
    "    if(temp < 0.8): ## 80% chance to start the sentence with a random word like for example \"war\"\n",
    "        pronoun = '' ## 20% chance to start the sentence with some extra words, like \"The war\" or \"in case of war\"\n",
    "    else:\n",
    "        with open('wordLists/startingWords.txt') as f:\n",
    "            pronouns = f.readlines()\n",
    "        pronoun = random.choice(pronouns)\n",
    "    \n",
    "    with open(random.choice(wordCategories)) as f: ## picks a random category\n",
    "        words = f.readlines() \n",
    "    random_word = pronoun + random.choice(words) ## picks a random word from that category\n",
    "    return random_word\n",
    "\n",
    "def removeDuplicates(sentence):\n",
    "    chars = list(sentence) ## if 2 duplicate words are next to each other, remove 1 of them\n",
    "    prev = None            ## so \"there is is is a fire fire\" --> \"there is a fire\"\n",
    "    k = 0\n",
    "    for c in sentence:\n",
    "        if prev != c:\n",
    "            chars[k] = c\n",
    "            prev = c\n",
    "            k = k + 1\n",
    "    return ' '.join(chars[:k])\n",
    "\n",
    "def filterQuote(quote, wordList):\n",
    "    x = True\n",
    "    words = quote.split() ## turn quote string into an array of words\n",
    "    while x == True:\n",
    "        if words[-1] in wordList: ## check if last word of sentence is legal or not\n",
    "            words = words[:-1]    ## if illegal, simply remove it.\n",
    "        else:\n",
    "            x = False\n",
    "            \n",
    "    words = removeDuplicates(words) ## filter duplicates\n",
    "    filteredQuote = words.capitalize() + '.' ## capitalization and punctuation\n",
    "    filteredQuote = re.sub(r'\\bi\\b', 'I', filteredQuote) ## regex baby, turns \"i\" into \"I\"\n",
    "    return filteredQuote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ramon\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 :  An age of wisdom is the beginning of wisdom and wisdom is to be humble from the truth that the truth is.\n"
     ]
    }
   ],
   "source": [
    "startWord = 'an age'\n",
    "length = 20\n",
    "## not sure wether maxlen should be equal to number of words, or be longer. it was trained on maxlen ~= 80\n",
    "\n",
    "#outputQuote = generate_quote(startWord, num_words = length, model= model1, maxlen=length)\n",
    "#filteredQuote = filterQuote(outputQuote, illegalWordsList)\n",
    "#print(\"Model 1 : \",filteredQuote)\n",
    "outputQuote2 = generate_quote(startWord, num_words = length, model= model2, maxlen=80)\n",
    "filteredQuote2 = filterQuote(outputQuote2, illegalWords)\n",
    "print(\"Model 2 : \",filteredQuote2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly chosen starting word:  \n",
      "intelligence\n",
      "\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 80) for input KerasTensor(type_spec=TensorSpec(shape=(None, 80), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 81).\n",
      "Intelligence is the truth that we can be deceived by are the folly of those who hunger.\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Randomly chosen starting word:  don't forget that\n",
      "eons\n",
      "\n",
      "Don't forget that eons you can trust you to tell you how to do it is really good and I'm not going to be able to go.\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Randomly chosen starting word:  guitar solos\n",
      "Guitar solos is loud as jewish and I was a lot of time and I am thankful for.\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Randomly chosen starting word:  happiness\n",
      "\n",
      "Happiness is the truth that all the time is the supreme thing for the truth is the truth that he is not.\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Randomly chosen starting word:  faith\n",
      "\n",
      "Faith around the world we have been in the world and the world is the same thing that.\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < 5:\n",
    "    startingWord = chooseStartingWord(wordCategories)\n",
    "    print('Randomly chosen starting word: ',startingWord)\n",
    "    numberOfWords = random.randint(12,25)\n",
    "    startingWord = startingWord.strip()\n",
    "\n",
    "    outputQuote = generate_quote(startingWord, num_words = numberOfWords, model= model2, maxlen=maxlen)\n",
    "    filteredQuote = filterQuote(outputQuote, illegalWords)\n",
    "    print(filteredQuote)\n",
    "    \n",
    "    \n",
    "    i+= 1\n",
    "    print('------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
